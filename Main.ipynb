{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AiProject.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNJMeRWoTooNbEGS04/a2Wg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LsAeA3h5oTJT","executionInfo":{"status":"ok","timestamp":1607312268047,"user_tz":420,"elapsed":20118,"user":{"displayName":"FaceMask Detection","photoUrl":"","userId":"12852440114488614838"}},"outputId":"0f8e4047-3681-41e8-d4b3-8245c9e90257"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W4TDlNstoi6R"},"source":["# Imports here\n","import os\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","from torchvision.transforms import Compose, ToTensor\n","import itertools\n","\n","\n","class CustomDataset(Dataset):\n","    \"\"\" Masked faces dataset\n","        0 = 'mask'\n","        1 = 'human'\n","        2 = 'non-human'\n","    \"\"\"\n","\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","\n","        self.transformations = Compose([ToTensor()])\n","\n","    def __getitem__(self, key):\n","        return [\n","            self.transformations(self.dataset[key][0]),\n","            torch.tensor(self.dataset[key][1])\n","        ]\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","\n","datasetPath = \"/gdrive/My Drive/Ai Project Run to Cloud/Dataset\"\n","maskDatasetPath = datasetPath + \"/masked dataset\"\n","humanDatasetPath = datasetPath + \"/human dataset\"\n","nonHumanDatasetPath = datasetPath + \"/non-human dataset\"\n","preprocessedDataPath = datasetPath + \"/data.npy\"\n","resultsPath = datasetPath + \"/Results\"\n","modelName = \"timepass.t7\"\n","batchSize = 142\n","\n","\n","class Data:\n","    def __init__(self):\n","        self.data = []\n","        self.trainDataLoader = []\n","        self.validationDataLoader = []\n","        self.testDataLoader = []\n","        self.normalizedWeights = []\n","        self.labelsDict = {0: \"Masked Human\", 1: \"Human\", 2: \"Non-Human\"}\n","\n","    def buildData(self):\n","        # Mask Dataset\n","        for path in os.listdir(maskDatasetPath):\n","            print(maskDatasetPath + \"/\" + path)\n","            img = cv2.imread(maskDatasetPath + \"/\" + path, cv2.IMREAD_COLOR)\n","            img = cv2.resize(img, (100, 100))\n","            self.data.append([np.array(img), 0])\n","\n","        # Human Dataset\n","        for path in os.listdir(humanDatasetPath):\n","            print(humanDatasetPath + \"/\" + path)\n","            img = cv2.imread(humanDatasetPath + \"/\" + path, cv2.IMREAD_COLOR)\n","            img = cv2.resize(img, (100, 100))\n","            self.data.append([np.array(img), 1])\n","\n","        # Non Human Dataset\n","        for path in os.listdir(nonHumanDatasetPath):\n","            print(nonHumanDatasetPath + \"/\" + path)\n","            img = cv2.imread(nonHumanDatasetPath + \"/\" + path, cv2.IMREAD_COLOR)\n","            img = cv2.resize(img, (100, 100))\n","            self.data.append([np.array(img), 2])\n","\n","        np.random.shuffle(self.data)\n","        np.save(preprocessedDataPath, self.data)\n","\n","    def loadPreprocessedData(self):\n","        return np.load(preprocessedDataPath, allow_pickle=True)\n","\n","    def buildDataLoader(self, build=False):\n","        print(\"Build DataLoader\")\n","        if build:\n","            self.buildData()\n","        trainVal, test = train_test_split(self.loadPreprocessedData(), test_size=0.05, random_state=0)\n","        train, val = train_test_split(trainVal, test_size=0.15, random_state=0)\n","        trainDataset = CustomDataset(train)\n","        validationDataset = CustomDataset(val)\n","        testDataset = CustomDataset(test)\n","        self.trainDataLoader = DataLoader(trainDataset, batch_size=batchSize)\n","        self.validationDataLoader = DataLoader(validationDataset, batch_size=batchSize)\n","        self.testDataLoader = DataLoader(testDataset, batch_size=batchSize)\n","        trainMaskImages = 0\n","        trainHumanImages = 0\n","        trainNonHumanImages = 0\n","        for row in train:\n","            if row[1] == 0:\n","                trainMaskImages = trainMaskImages + 1\n","            elif row[1] == 1:\n","                trainHumanImages = trainHumanImages + 1\n","            else:\n","                trainNonHumanImages = trainNonHumanImages + 1\n","\n","        numberOfImagesByCategory = [trainMaskImages, trainHumanImages, trainNonHumanImages]\n","        self.normalizedWeights = [1 - (x / sum(numberOfImagesByCategory)) for x in numberOfImagesByCategory]\n","        print(\"Normalized Weights: \", self.normalizedWeights)\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","      print(\"Building CNN\")\n","      super().__init__()\n","      self.network = nn.Sequential(\n","          nn.Conv2d(3, 100, kernel_size=3, padding=1),\n","          nn.BatchNorm2d(100),\n","          nn.ReLU(inplace=True),\n","          nn.Conv2d(100, 128, kernel_size=3, stride=1, padding=1),\n","          nn.BatchNorm2d(128),\n","          nn.ReLU(inplace=True),\n","          nn.MaxPool2d(2, 2),  # output: 128 x 8 x 8\n","          nn.Dropout2d(p=0.05),\n","\n","          nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","          nn.BatchNorm2d(256),\n","          nn.ReLU(inplace=True),\n","          nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n","          nn.BatchNorm2d(512),\n","          nn.ReLU(inplace=True),\n","          nn.MaxPool2d(2, 2),  # output: 512 x 25 x 25\n","          nn.Dropout2d(p=0.05),\n","\n","          nn.Flatten(),\n","          nn.Linear(320000, 512), # 512 x 25 x 25 = 320000\n","          nn.ReLU(inplace=True),\n","          nn.Dropout2d(p=0.2),\n","          nn.Linear(512, 256),\n","          nn.ReLU(inplace=True),\n","          nn.Dropout2d(p=0.2),\n","          nn.Linear(256, 3))\n","\n","    def forward(self, xb):\n","      return self.network(xb)\n","\n","\n","class TrainTest:\n","    def __init__(self, normalizedWeights, model: CNN):\n","        self.model = model.to(self.getDevice())\n","        self.crossEntropyLoss = nn.CrossEntropyLoss(weight=torch.tensor(normalizedWeights).to(self.getDevice()))\n","        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","\n","    def moveToDevice(self, content, newDevice):\n","        if isinstance(content, list):\n","            return [self.moveToDevice(x, newDevice) for x in content]\n","        return content.to(newDevice, non_blocking=True)\n","\n","    def accuracy(self, outputs, labels):\n","        _, predictions = torch.max(outputs, dim=1)\n","        return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n","\n","    def validationPhase(self, batch):\n","        with torch.no_grad():\n","            images, labels = batch\n","            outputs = self.model(images)\n","            loss = self.crossEntropyLoss(outputs, labels.long())\n","            validationAccuracy = self.accuracy(outputs, labels)\n","            return [validationAccuracy, loss]\n","\n","    def validationEnd(self, outputs):\n","        batchLoss = [output[1] for output in outputs]\n","        batchAcc = [output[0] for output in outputs]\n","        epochLoss = torch.stack(batchLoss).mean()\n","        epochAcc = torch.stack(batchAcc).mean()\n","        return [epochLoss.item(), epochAcc.item()]\n","\n","    def testModel(self, dataLoader):\n","        self.model.eval()\n","        with torch.no_grad():\n","            outputs = []\n","            for batch in dataLoader:\n","                batch = self.moveToDevice(batch, self.getDevice())\n","                outputs.append(self.validationPhase(batch))\n","            return self.validationEnd(outputs)\n","\n","    def trainModel(self, epochs, data):\n","      print(\"Training Model\")\n","      epochResults = []\n","      tolerance = 1e-4\n","      prevValLoss = 1\n","      for epoch in range(epochs):\n","          self.model.train()\n","          trainAccuracies = []\n","          trainLosses = []\n","\n","          # TRAIN STEP\n","          for batch in data.trainDataLoader:\n","              batch = self.moveToDevice(batch, self.getDevice())\n","              images, labels = batch\n","              outputs = self.model(images)\n","              trainLoss = self.crossEntropyLoss(outputs, labels.long())\n","              trainAcc = self.accuracy(outputs, labels)\n","              trainAccuracies.append(trainAcc)\n","              trainLosses.append(trainLoss)\n","              trainLoss.backward()\n","              self.optimizer.step()\n","              self.optimizer.zero_grad()\n","\n","          # VALIDATION STEP\n","          validationLoss, validationAcc = self.testModel(data.validationDataLoader)\n","          # RESULTS\n","          result = [torch.stack(trainAccuracies).mean().item(), torch.stack(trainLosses).mean().item(),\n","                    validationLoss, validationAcc]\n","          epochResults.append(result)\n","\n","          # Print Result\n","          print(\"Epoch: {}, trainLoss: {:.4f}, trainAcc: {:.4f}, valLoss: {:.4f}, valAcc: {:.4f}\"\n","                .format(epoch, result[1], result[0], result[2], result[3]))\n","\n","          # SAVE MODEL\n","          if prevValLoss - validationLoss > tolerance:\n","              prevValLoss = validationLoss\n","              print('==> Saving model ...')\n","              state = {\n","                  'net': self.model,\n","                  'epoch': epoch,\n","                  'state_dict': self.model.state_dict()\n","              }\n","              torch.save(state, datasetPath + \"/\" + modelName)\n","      return epochResults\n","\n","    def getDevice(self):\n","        isCudaAvailable = torch.cuda.is_available()\n","        device = torch.device('cuda') if isCudaAvailable else torch.device('cpu')\n","        return device\n","\n","    def loadModel(self):\n","        loadedModel = torch.load(datasetPath + \"/\" + modelName, map_location=self.getDevice())\n","        self.model = CNN()\n","        self.model.load_state_dict(loadedModel[\"state_dict\"])\n","        self.model = self.model.to(self.getDevice())\n","\n","    def evaluate(self, dataLoader):\n","        predictionLabels = []\n","        actualLabels = []\n","        self.model.eval()\n","        with torch.no_grad():\n","            for batch in dataLoader:\n","                batch = self.moveToDevice(batch, self.getDevice())\n","                images, labels = batch\n","                outputs = self.model(images)\n","                _, predictions = torch.max(outputs, dim=1)\n","                predictionLabels.append(predictions.detach().cpu().numpy())\n","                actualLabels.append(labels.detach().cpu().numpy())\n","        return [item for sublist in predictionLabels for item in sublist], [item for sublist in actualLabels for item in\n","                                                                            sublist]\n","\n","    def printClassificationReportAndPlotConfusionMatrix(self, data):\n","        classes = [\"Masked Human\", \"Human\", \"Non-Human\"]\n","        print(\"Test Classification Report\")\n","        testPredictionLabels, testActualLabels = self.evaluate(data.testDataLoader)\n","        print(classification_report(testActualLabels, testPredictionLabels))\n","        self.plot_confusion_matrix(confusion_matrix(testActualLabels, testPredictionLabels), classes,\n","                                   title=\"Test Confusion Matrix\")\n","\n","        print(\"Validation Classification Report\")\n","        validationPredictionLabels, validationActualLabels = self.evaluate(data.validationDataLoader)\n","        print(classification_report(validationActualLabels, validationPredictionLabels))\n","        self.plot_confusion_matrix(confusion_matrix(validationActualLabels, validationPredictionLabels), classes,\n","                                   title=\"Validation Confusion Matrix\")\n","        \n","        print(\"Train Classification Report\")\n","        trainPredictionLabels, trainActualLabels = self.evaluate(data.trainDataLoader)\n","        print(classification_report(trainActualLabels, trainPredictionLabels))\n","        self.plot_confusion_matrix(confusion_matrix(trainActualLabels, trainPredictionLabels), classes,\n","                                   title=\"Train Confusion Matrix\")\n","\n","    def plot_confusion_matrix(self, cm, classes, normalize=False, title='Confusion matrix',\n","                            cmap=plt.cm.Blues):\n","        \"\"\"\n","        This function prints and plots the confusion matrix.\n","        Normalization can be applied by setting `normalize=True`.\n","        \"\"\"\n","        plt.figure()\n","        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","        plt.title(title)\n","        plt.colorbar()\n","        tick_marks = np.arange(len(classes))\n","        plt.xticks(tick_marks, classes, rotation=45)\n","        plt.yticks(tick_marks, classes)\n","\n","        if normalize:\n","            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","        thresh = cm.max() / 2.\n","        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","            plt.text(j, i, cm[i, j],\n","                      horizontalalignment=\"center\",\n","                      color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","        plt.axis('scaled')\n","        plt.ylabel('True label')\n","        plt.xlabel('Predicted label')\n","        plt.savefig(resultsPath + \"/\" + title)\n","\n","    def plotTestPredictions(self, data):\n","        testPredictionLabels, testActualLabels = self.evaluate(data.testDataLoader)\n","        f, axarr = plt.subplots(1, 10, figsize=(100, 100))\n","        for batch in data.testDataLoader:\n","            images, labels = batch\n","            for i in range(10):\n","                img = images[i].detach().cpu().numpy().transpose(1, 2, 0)\n","                axarr[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","                axarr[i].set_title(\"PL: {0}, AL: {1}\".format(testPredictionLabels[i], testActualLabels[i]))\n","                axarr[i].set_xticks([])\n","                axarr[i].set_yticks([])\n","            plt.show(block=True)\n","            f.savefig(resultsPath + \"/Test-Predictions.png\")\n","            break\n","\n","trainModel = True\n","plotTestingPredictions = False\n","buildData = False\n","dataObject = Data()\n","dataObject.buildDataLoader(buildData)\n","cnn = CNN()\n","trainTest = TrainTest(dataObject.normalizedWeights, cnn)\n","if trainModel:\n","  trainTest.trainModel(10, dataObject)\n","trainTest.loadModel()\n","trainTest.printClassificationReportAndPlotConfusionMatrix(dataObject)\n","if plotTestingPredictions:\n","  trainTest.plotTestPredictions(dataObject)\n"],"execution_count":null,"outputs":[]}]}